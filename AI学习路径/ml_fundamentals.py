"""
æœºå™¨å­¦ä¹ åŸºç¡€æ¦‚å¿µå’Œç®—æ³•å®ç°
é€‚åˆJavaå¼€å‘è€…ç†è§£çš„MLæ ¸å¿ƒæ¦‚å¿µ
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix
import seaborn as sns

class MachineLearningBasics:
    """æœºå™¨å­¦ä¹ åŸºç¡€æ¦‚å¿µæ¼”ç¤º"""
    
    def __init__(self):
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
    
    def generate_sample_data(self):
        """ç”Ÿæˆç¤ºä¾‹æ•°æ®é›†"""
        # åˆ›å»ºäºŒåˆ†ç±»æ•°æ®é›†
        X, y = make_classification(
            n_samples=1000,
            n_features=2,
            n_redundant=0,
            n_informative=2,
            n_clusters_per_class=1,
            random_state=42
        )
        
        # åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            X, y, test_size=0.3, random_state=42
        )
        
        return self.X_train, self.y_train
    
    def linear_regression_explanation(self):
        """çº¿æ€§å›å½’åŸç†è¯´æ˜"""
        print("=== çº¿æ€§å›å½’åŸç† ===")
        print("ç›®æ ‡ï¼šæ‰¾åˆ°æœ€ä½³æ‹Ÿåˆç›´çº¿ y = wx + b")
        print("æŸå¤±å‡½æ•°ï¼šå‡æ–¹è¯¯å·® MSE = Î£(yi - (wx + b))Â²/n")
        print("ä¼˜åŒ–æ–¹æ³•ï¼šæ¢¯åº¦ä¸‹é™æ³•")
        
        # ç®€å•å®ç°
        class SimpleLinearRegression:
            def __init__(self, learning_rate=0.01, n_iterations=1000):
                self.learning_rate = learning_rate
                self.n_iterations = n_iterations
                self.weight = 0
                self.bias = 0
            
            def fit(self, X, y):
                n_samples = len(X)
                # æ¢¯åº¦ä¸‹é™
                for _ in range(self.n_iterations):
                    y_predicted = self.weight * X + self.bias
                    
                    # è®¡ç®—æ¢¯åº¦
                    dw = (1/n_samples) * np.sum(X * (y_predicted - y))
                    db = (1/n_samples) * np.sum(y_predicted - y)
                    
                    # æ›´æ–°å‚æ•°
                    self.weight -= self.learning_rate * dw
                    self.bias -= self.learning_rate * db
            
            def predict(self, X):
                return self.weight * X + self.bias
        
        return SimpleLinearRegression()
    
    def logistic_regression_demo(self):
        """é€»è¾‘å›å½’æ¼”ç¤ºï¼ˆåˆ†ç±»ç®—æ³•ï¼‰"""
        print("\n=== é€»è¾‘å›å½’æ¼”ç¤º ===")
        
        # ä½¿ç”¨sklearnå®ç°
        model = LogisticRegression(random_state=42)
        model.fit(self.X_train, self.y_train)
        
        # é¢„æµ‹
        y_pred = model.predict(self.X_test)
        accuracy = accuracy_score(self.y_test, y_pred)
        
        print(f"æ¨¡å‹å‡†ç¡®ç‡: {accuracy:.4f}")
        
        # å¯è§†åŒ–å†³ç­–è¾¹ç•Œ
        self.visualize_decision_boundary(model)
        
        return model, accuracy
    
    def visualize_decision_boundary(self, model):
        """å¯è§†åŒ–å†³ç­–è¾¹ç•Œ"""
        plt.figure(figsize=(10, 8))
        
        # ç»˜åˆ¶æ•°æ®ç‚¹
        scatter = plt.scatter(self.X_test[:, 0], self.X_test[:, 1], 
                            c=self.y_test, cmap='viridis', alpha=0.7)
        
        # åˆ›å»ºç½‘æ ¼ç‚¹
        h = 0.02
        x_min, x_max = self.X_test[:, 0].min() - 1, self.X_test[:, 0].max() + 1
        y_min, y_max = self.X_test[:, 1].min() - 1, self.X_test[:, 1].max() + 1
        xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                            np.arange(y_min, y_max, h))
        
        # é¢„æµ‹ç½‘æ ¼ç‚¹
        Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
        Z = Z.reshape(xx.shape)
        
        # ç»˜åˆ¶å†³ç­–è¾¹ç•Œ
        plt.contour(xx, yy, Z, levels=[0.5], colors='red', linewidths=2)
        plt.colorbar(scatter)
        plt.xlabel('ç‰¹å¾1')
        plt.ylabel('ç‰¹å¾2')
        plt.title('é€»è¾‘å›å½’å†³ç­–è¾¹ç•Œ')
        plt.savefig('decision_boundary.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def supervised_vs_unsupervised(self):
        """ç›‘ç£å­¦ä¹ vsæ— ç›‘ç£å­¦ä¹ """
        print("\n=== å­¦ä¹ æ–¹å¼å¯¹æ¯” ===")
        
        supervised_methods = {
            "ç›‘ç£å­¦ä¹ ": [
                "çº¿æ€§å›å½’ - é¢„æµ‹è¿ç»­å€¼",
                "é€»è¾‘å›å½’ - äºŒåˆ†ç±»é—®é¢˜",
                "å†³ç­–æ ‘ - åˆ†ç±»å’Œå›å½’",
                "éšæœºæ£®æ— - é›†æˆå­¦ä¹ ",
                "æ”¯æŒå‘é‡æœº - åˆ†ç±»å’Œå›å½’",
                "ç¥ç»ç½‘ç»œ - å¤æ‚æ¨¡å¼è¯†åˆ«"
            ]
        }
        
        unsupervised_methods = {
            "æ— ç›‘ç£å­¦ä¹ ": [
                "K-meansèšç±» - æ•°æ®åˆ†ç»„",
                "å±‚æ¬¡èšç±» - æ ‘çŠ¶åˆ†ç»„",
                "ä¸»æˆåˆ†åˆ†æ(PCA) - é™ç»´",
                "å…³è”è§„åˆ™ - è´­ç‰©ç¯®åˆ†æ",
                "è‡ªç¼–ç å™¨ - ç‰¹å¾å­¦ä¹ "
            ]
        }
        
        print("ç›‘ç£å­¦ä¹ åº”ç”¨åœºæ™¯ï¼š")
        for method in supervised_methods["ç›‘ç£å­¦ä¹ "]:
            print(f"  â€¢ {method}")
            
        print("\næ— ç›‘ç£å­¦ä¹ åº”ç”¨åœºæ™¯ï¼š")
        for method in unsupervised_methods["æ— ç›‘ç£å­¦ä¹ "]:
            print(f"  â€¢ {method}")

class MLWorkflowDemo:
    """æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹æ¼”ç¤º"""
    
    def __init__(self):
        self.steps = [
            "1. é—®é¢˜å®šä¹‰å’Œæ•°æ®æ”¶é›†",
            "2. æ•°æ®é¢„å¤„ç†å’Œæ¸…æ´—",
            "3. æ¢ç´¢æ€§æ•°æ®åˆ†æ(EDA)",
            "4. ç‰¹å¾å·¥ç¨‹",
            "5. æ¨¡å‹é€‰æ‹©å’Œè®­ç»ƒ",
            "6. æ¨¡å‹è¯„ä¼°å’ŒéªŒè¯",
            "7. æ¨¡å‹éƒ¨ç½²å’Œç›‘æ§"
        ]
    
    def show_workflow(self):
        """å±•ç¤ºå®Œæ•´çš„MLå·¥ä½œæµç¨‹"""
        print("\n=== æœºå™¨å­¦ä¹ æ ‡å‡†å·¥ä½œæµç¨‹ ===")
        for step in self.steps:
            print(step)
    
    def preprocessing_example(self):
        """æ•°æ®é¢„å¤„ç†ç¤ºä¾‹"""
        print("\n=== æ•°æ®é¢„å¤„ç†ç¤ºä¾‹ ===")
        
        # æ¨¡æ‹ŸåŸå§‹æ•°æ®
        raw_data = np.array([
            [1.2, 3.4, np.nan],
            [2.1, np.nan, 5.6],
            [np.nan, 4.5, 6.7],
            [3.2, 5.6, 7.8]
        ])
        
        print("åŸå§‹æ•°æ®:")
        print(raw_data)
        
        # å¤„ç†ç¼ºå¤±å€¼
        from sklearn.impute import SimpleImputer
        imputer = SimpleImputer(strategy='mean')
        clean_data = imputer.fit_transform(raw_data)
        
        print("\nå¤„ç†åçš„æ•°æ®:")
        print(clean_data)
        
        # ç‰¹å¾ç¼©æ”¾
        from sklearn.preprocessing import StandardScaler
        scaler = StandardScaler()
        scaled_data = scaler.fit_transform(clean_data)
        
        print("\næ ‡å‡†åŒ–åçš„æ•°æ®:")
        print(scaled_data)
        
        return scaled_data

def main():
    """ä¸»å‡½æ•°æ¼”ç¤º"""
    print("ğŸ¤– æœºå™¨å­¦ä¹ åŸºç¡€æ¦‚å¿µæ¼”ç¤º")
    print("=" * 50)
    
    # åˆå§‹åŒ–
    ml_basics = MachineLearningBasics()
    
    # ç”Ÿæˆæ•°æ®
    print("æ­£åœ¨ç”Ÿæˆç¤ºä¾‹æ•°æ®...")
    X_train, y_train = ml_basics.generate_sample_data()
    print(f"è®­ç»ƒæ•°æ®å½¢çŠ¶: {X_train.shape}")
    
    # çº¿æ€§å›å½’æ¼”ç¤º
    lr_model = ml_basics.linear_regression_explanation()
    
    # é€»è¾‘å›å½’æ¼”ç¤º
    log_model, accuracy = ml_basics.logistic_regression_demo()
    
    # å­¦ä¹ æ–¹å¼å¯¹æ¯”
    ml_basics.supervised_vs_unsupervised()
    
    # å·¥ä½œæµç¨‹æ¼”ç¤º
    workflow = MLWorkflowDemo()
    workflow.show_workflow()
    workflow.preprocessing_example()
    
    print("\nâœ… æœºå™¨å­¦ä¹ åŸºç¡€æ¦‚å¿µæ¼”ç¤ºå®Œæˆï¼")

if __name__ == "__main__":
    main()
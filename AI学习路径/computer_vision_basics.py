"""
è®¡ç®—æœºè§†è§‰åŸºç¡€æ•™ç¨‹
é¢å‘Javaå¼€å‘è€…çš„CVå…¥é—¨æŒ‡å—
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import requests
from io import BytesIO

class ComputerVisionBasics:
    """è®¡ç®—æœºè§†è§‰åŸºç¡€æ¦‚å¿µ"""
    
    def __init__(self):
        self.sample_image_url = "https://upload.wikimedia.org/wikipedia/commons/thumb/5/50/Vd-Orig.png/256px-Vd-Orig.png"
    
    def image_processing_fundamentals(self):
        """å›¾åƒå¤„ç†åŸºç¡€"""
        print("=== å›¾åƒå¤„ç†åŸºç¡€ ===")
        
        # åˆ›å»ºç¤ºä¾‹å›¾åƒ
        img = np.zeros((300, 300, 3), dtype=np.uint8)
        img[100:200, 100:200] = [255, 0, 0]  # çº¢è‰²çŸ©å½¢
        img[150:250, 150:250] = [0, 255, 0]  # ç»¿è‰²çŸ©å½¢
        
        # æ˜¾ç¤ºå›¾åƒä¿¡æ¯
        print(f"å›¾åƒå½¢çŠ¶: {img.shape}")
        print(f"å›¾åƒæ•°æ®ç±»å‹: {img.dtype}")
        print(f"åƒç´ å€¼èŒƒå›´: {img.min()} - {img.max()}")
        
        return img
    
    def image_filters_demo(self, img):
        """å›¾åƒæ»¤æ³¢å™¨æ¼”ç¤º"""
        print("\n=== å›¾åƒæ»¤æ³¢å™¨ ===")
        
        # 1. é«˜æ–¯æ¨¡ç³Š
        blurred = cv2.GaussianBlur(img, (15, 15), 0)
        
        # 2. è¾¹ç¼˜æ£€æµ‹
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        edges = cv2.Canny(gray, 50, 150)
        
        # 3. å½¢æ€å­¦æ“ä½œ
        kernel = np.ones((5,5), np.uint8)
        dilated = cv2.dilate(edges, kernel, iterations=1)
        
        return blurred, edges, dilated
    
    def feature_detection(self, img):
        """ç‰¹å¾æ£€æµ‹"""
        print("\n=== ç‰¹å¾æ£€æµ‹ ===")
        
        # è½¬æ¢ä¸ºç°åº¦å›¾
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # Harrisè§’ç‚¹æ£€æµ‹
        gray_float = np.float32(gray)
        corners = cv2.cornerHarris(gray_float, 2, 3, 0.04)
        corners = cv2.dilate(corners, None)
        
        # æ ‡è®°è§’ç‚¹
        img_corners = img.copy()
        img_corners[corners > 0.01 * corners.max()] = [0, 0, 255]
        
        return img_corners

class ObjectDetectionBasics:
    """ç›®æ ‡æ£€æµ‹åŸºç¡€"""
    
    def simple_object_detection(self):
        """ç®€å•ç›®æ ‡æ£€æµ‹ç¤ºä¾‹"""
        print("\n=== ç®€å•ç›®æ ‡æ£€æµ‹ ===")
        
        # åˆ›å»ºåŒ…å«å¤šä¸ªå¯¹è±¡çš„å›¾åƒ
        img = np.zeros((400, 400, 3), dtype=np.uint8)
        
        # æ·»åŠ ä¸åŒé¢œè‰²çš„åœ†å½¢ï¼ˆæ¨¡æ‹Ÿä¸åŒå¯¹è±¡ï¼‰
        cv2.circle(img, (100, 100), 30, (255, 0, 0), -1)    # è“è‰²åœ†
        cv2.circle(img, (250, 150), 40, (0, 255, 0), -1)    # ç»¿è‰²åœ†
        cv2.circle(img, (180, 300), 35, (0, 0, 255), -1)    # çº¢è‰²åœ†
        
        # è½¬æ¢ä¸ºHSVè‰²å½©ç©ºé—´è¿›è¡Œé¢œè‰²åˆ†å‰²
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        
        # å®šä¹‰è“è‰²èŒƒå›´
        lower_blue = np.array([100, 50, 50])
        upper_blue = np.array([130, 255, 255])
        blue_mask = cv2.inRange(hsv, lower_blue, upper_blue)
        
        # æŸ¥æ‰¾è½®å»“
        contours, _ = cv2.findContours(blue_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # åœ¨åŸå›¾ä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ
        result_img = img.copy()
        for contour in contours:
            # è®¡ç®—è½®å»“çš„è¾¹ç•Œæ¡†
            x, y, w, h = cv2.boundingRect(contour)
            cv2.rectangle(result_img, (x, y), (x+w, y+h), (255, 255, 255), 2)
            cv2.putText(result_img, "Object", (x, y-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        print(f"æ£€æµ‹åˆ° {len(contours)} ä¸ªè“è‰²å¯¹è±¡")
        return result_img

class DeepLearningCV:
    """æ·±åº¦å­¦ä¹ è®¡ç®—æœºè§†è§‰"""
    
    def pretrained_model_demo(self):
        """é¢„è®­ç»ƒæ¨¡å‹æ¼”ç¤º"""
        print("\n=== é¢„è®­ç»ƒæ¨¡å‹æ¼”ç¤º ===")
        
        try:
            # ä½¿ç”¨OpenCVçš„DNNæ¨¡å—åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
            # è¿™é‡Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬ï¼Œå®é™…åº”ç”¨ä¸­å¯ä»¥ä½¿ç”¨YOLOã€ResNetç­‰
            
            print("é¢„è®­ç»ƒæ¨¡å‹ç±»åˆ«:")
            classes = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus']
            for i, cls in enumerate(classes[:3]):
                print(f"  {i}: {cls}")
            
            # æ¨¡æ‹Ÿæ£€æµ‹ç»“æœ
            detections = [
                {"class": "person", "confidence": 0.95, "bbox": [50, 50, 150, 200]},
                {"class": "car", "confidence": 0.87, "bbox": [200, 100, 300, 180]}
            ]
            
            print("\næ£€æµ‹ç»“æœ:")
            for det in detections:
                print(f"  ç±»åˆ«: {det['class']}, ç½®ä¿¡åº¦: {det['confidence']:.2f}")
                print(f"  è¾¹ç•Œæ¡†: {det['bbox']}")
                
        except Exception as e:
            print(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("è¯·å®‰è£…: pip install opencv-python")

class CVApplications:
    """è®¡ç®—æœºè§†è§‰åº”ç”¨"""
    
    def face_detection_demo(self):
        """äººè„¸æ£€æµ‹æ¼”ç¤º"""
        print("\n=== äººè„¸æ£€æµ‹æ¼”ç¤º ===")
        
        # åˆ›å»ºç¤ºä¾‹äººè„¸å›¾åƒ
        face_img = np.zeros((200, 200, 3), dtype=np.uint8)
        # ç»˜åˆ¶ç®€åŒ–çš„è„¸éƒ¨ç‰¹å¾
        cv2.circle(face_img, (100, 80), 60, (135, 206, 235), -1)  # è„¸éƒ¨
        cv2.circle(face_img, (70, 70), 10, (0, 0, 0), -1)         # å·¦çœ¼
        cv2.circle(face_img, (130, 70), 10, (0, 0, 0), -1)        # å³çœ¼
        cv2.ellipse(face_img, (100, 120), (25, 15), 0, 0, 180, (0, 0, 0), 2)  # å˜´å·´
        
        print("äººè„¸æ£€æµ‹åŸºæœ¬åŸç†:")
        print("1. Haarç‰¹å¾æ£€æµ‹")
        print("2. LBPå±€éƒ¨äºŒå€¼æ¨¡å¼")
        print("3. æ·±åº¦å­¦ä¹ æ–¹æ³•(CNN)")
        
        return face_img
    
    def image_classification_pipeline(self):
        """å›¾åƒåˆ†ç±»æµæ°´çº¿"""
        print("\n=== å›¾åƒåˆ†ç±»æµæ°´çº¿ ===")
        
        pipeline_steps = [
            "1. å›¾åƒé‡‡é›†",
            "2. é¢„å¤„ç†(ç¼©æ”¾ã€å½’ä¸€åŒ–)",
            "3. æ•°æ®å¢å¼º",
            "4. ç‰¹å¾æå–",
            "5. æ¨¡å‹è®­ç»ƒ",
            "6. éªŒè¯å’Œæµ‹è¯•",
            "7. éƒ¨ç½²æ¨ç†"
        ]
        
        for step in pipeline_steps:
            print(step)

def display_images(images_dict):
    """æ˜¾ç¤ºå›¾åƒç»“æœ"""
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    axes = axes.ravel()
    
    for idx, (title, img) in enumerate(images_dict.items()):
        if idx < len(axes):
            # è½¬æ¢BGRåˆ°RGBç”¨äºmatplotlibæ˜¾ç¤º
            if len(img.shape) == 3:
                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            else:
                img_rgb = img
            axes[idx].imshow(img_rgb, cmap='gray' if len(img.shape) == 2 else None)
            axes[idx].set_title(title)
            axes[idx].axis('off')
    
    plt.tight_layout()
    plt.savefig('cv_demonstration.png', dpi=300, bbox_inches='tight')
    plt.show()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ‘ï¸ è®¡ç®—æœºè§†è§‰åŸºç¡€æ•™ç¨‹")
    print("=" * 50)
    
    # åŸºç¡€CVæ“ä½œ
    cv_basic = ComputerVisionBasics()
    original_img = cv_basic.image_processing_fundamentals()
    
    # å›¾åƒæ»¤æ³¢
    blurred, edges, dilated = cv_basic.image_filters_demo(original_img)
    
    # ç‰¹å¾æ£€æµ‹
    corner_img = cv_basic.feature_detection(original_img)
    
    # ç›®æ ‡æ£€æµ‹
    obj_detection = ObjectDetectionBasics()
    detection_result = obj_detection.simple_object_detection()
    
    # æ·±åº¦å­¦ä¹ CV
    dl_cv = DeepLearningCV()
    dl_cv.pretrained_model_demo()
    
    # CVåº”ç”¨
    applications = CVApplications()
    face_img = applications.face_detection_demo()
    applications.image_classification_pipeline()
    
    # æ˜¾ç¤ºç»“æœï¼ˆå¦‚æœç¯å¢ƒæ”¯æŒï¼‰
    try:
        images_to_show = {
            "åŸå§‹å›¾åƒ": original_img,
            "é«˜æ–¯æ¨¡ç³Š": blurred,
            "è¾¹ç¼˜æ£€æµ‹": edges,
            "è§’ç‚¹æ£€æµ‹": corner_img,
            "ç›®æ ‡æ£€æµ‹": detection_result,
            "äººè„¸ç¤ºä¾‹": face_img
        }
        display_images(images_to_show)
    except:
        print("å›¾åƒæ˜¾ç¤ºéœ€è¦matplotlibæ”¯æŒ")
    
    print("\nâœ… è®¡ç®—æœºè§†è§‰åŸºç¡€å­¦ä¹ å®Œæˆï¼")

if __name__ == "__main__":
    main()